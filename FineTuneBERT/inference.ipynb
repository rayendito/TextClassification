{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install dataset transformers evaluate huggingface_hub pytorch torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer, BertForSequenceClassification, BertTokenizer, TextClassificationPipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data\n",
    "data = load_dataset(\"./sentiment_dataset_loader.py\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load indobert tokenizer and model (finetuned for a little bit)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"indolem/indobert-base-uncased\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"./saved_model/\", num_labels=2)\n",
    "model_pure = AutoModelForSequenceClassification.from_pretrained(\"indolem/indobert-base-uncased\", num_labels=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.config.id2label = {\n",
    "    0: 'no',\n",
    "    1: 'yes'\n",
    "}\n",
    "\n",
    "model_pure.config.id2label = {\n",
    "    0: 'no',\n",
    "    1: 'yes'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "finetuned_pipeline = TextClassificationPipeline(model=model, tokenizer=tokenizer)\n",
    "pure_pipeline = TextClassificationPipeline(model=model_pure, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': ['btw td malem keperluan gila pusdai pasar malem rame bgt sampe bikin macet sedih kesel liatnya gaada physical distancing',\n",
       "  'lebaran nya jakarta',\n",
       "  'bengek ga gini ya presiden btw missread uname mu presiden serius https t co igmvydowlj',\n",
       "  'presiden tegaskan serius tangani wabah corona jakarta https t co xazozzyvae ak presiden joko widodo pemerintah mengambil langkah pencegahan sertaa ak https t co ow1ysq9ncz https t co lji2bn5ral',\n",
       "  'corona please cape jd jahat dunia',\n",
       "  'dibalik wabah virus corona hikmah yg diambil orang2 peduli kesehatan yg batuk bersin sembarangan suka disengajain dikenain orang memilih ditutup mulut nya pilih menjauh',\n",
       "  'arikurn76 arief luarbiasa yamansetiawan89 petijoged detikcom physical distancing tuh video dempetan smua',\n",
       "  'msaid didu setuju new presiden',\n",
       "  'trueind26978997 babitaphogat waha k prince ki khud ftti pdi h corona',\n",
       "  'corona selesai rampok maling begal horor banget'],\n",
       " 'label': [0, 0, 0, 1, 0, 1, 0, 0, 0, 1]}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['train'].shuffle(seed=42)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': ['betewe buka twitter cuman ngetweet liat home berita corona panik kepikiran ndamau buka2 home yg aware aja i ll stay at home nda rumah kalo nda penting2 banget',\n",
       "  'mas piyuuu mugo2 corona tuh mulut tersumpal ma corona',\n",
       "  'e100ss gini buka informasi sejelas nya identitas daerah penderita terjangkit infokan masyarakat mengisolasi nya kontak langsung penderita positif corona ditutup tutupi',\n",
       "  'neng solo wes ono terduga corona cobo neng ati mu neng conora',\n",
       "  'midiahn nii akun gak takut takut nya isu corona wkwkwkw',\n",
       "  'hey corona prrgi sna',\n",
       "  'gara corona masuk ketempat aja mesti scan jidat gw kek jajanan indomaret',\n",
       "  'jokowi menteri2 nya silakan tes corona',\n",
       "  'pencegahan corona other moms minum multivitamin my mom minum rebusan sambiloto',\n",
       "  'mamaciaaa mnrut gue jngan dkt2 corona cb dkt yg y puspa jaya damri als dkt tran jakarta aj'],\n",
       " 'label': [0, 0, 1, 0, 0, 0, 0, 1, 1, 0]}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['train'][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': ['amaliyatussilmi intandetris deliv depok jg',\n",
       "  'grosir masker spirulina depok sms wa 082258435266 line',\n",
       "  'buka data hp disalahin gak membantu nyalah2in kondisi kesehatan pasien positif corona depok dirawat rspi sulianti saroso membaik wali kota depok menyebut nya mengalami stres',\n",
       "  'ramayanads ezash ramayana aja min depok graha cijantung',\n",
       "  'pt kai commuter jabodetabek mengaku antisipasi virus corona membagi masker stasiun serat mengeluarkan imbauan khusus nya distasiun depok bumnsiaplawancorona ntap',\n",
       "  'lgi marak virus corona diindo nya depok direktur kantor org depok waswas gitu pagi disediain jamu jahe dibeliin langsung nya disediain ditiap meja dipastiin smua karyawan nya minum jamu',\n",
       "  'nya langkah cepat bumnsiaplawancorona khusus nya daerah depok bumn farmasi diperintahkan menjaga ketersediaan stok menjaga stabilitas harga alat pelindung cairan antiseptik alat sanitasi 4y4nkz jr kw19 rizmawidiono',\n",
       "  'kemaren angkot pas mangga anak nya gue mah yg kena virus kemaren dimana srot2 ingus depok ya salaman ya org depok ketularan heh anak nya dritadi srat srot mulu ya',\n",
       "  'kepedulian bumn negeri bank mandiri membagikan 10 000 masker lokasi kota depok bumnsiaplawancorona ntap',\n",
       "  'ramayanads ni ramayana depok gaaaaa'],\n",
       " 'label': [0, 0, 1, 0, 1, 0, 1, 0, 1, 0]}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['test'][10:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'no', 'score': 0.7027825713157654},\n",
       " {'label': 'no', 'score': 0.7027825713157654},\n",
       " {'label': 'no', 'score': 0.7027904391288757},\n",
       " {'label': 'no', 'score': 0.7027826309204102},\n",
       " {'label': 'no', 'score': 0.7026005387306213},\n",
       " {'label': 'no', 'score': 0.702782928943634},\n",
       " {'label': 'no', 'score': 0.7027844190597534},\n",
       " {'label': 'no', 'score': 0.7027825713157654},\n",
       " {'label': 'no', 'score': 0.7027592658996582},\n",
       " {'label': 'no', 'score': 0.7027825713157654}]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finetuned_pipeline(data['test'][10:20]['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'no', 'score': 0.53199702501297},\n",
       " {'label': 'yes', 'score': 0.5768569111824036},\n",
       " {'label': 'yes', 'score': 0.5420094132423401},\n",
       " {'label': 'yes', 'score': 0.55599045753479},\n",
       " {'label': 'yes', 'score': 0.5015228986740112},\n",
       " {'label': 'yes', 'score': 0.6366876363754272},\n",
       " {'label': 'yes', 'score': 0.6327794790267944},\n",
       " {'label': 'yes', 'score': 0.5367988348007202},\n",
       " {'label': 'yes', 'score': 0.5547583699226379},\n",
       " {'label': 'yes', 'score': 0.5676892399787903}]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pure_pipeline(data['test'][10:20]['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "asd = pd.read_csv('https://raw.githubusercontent.com/nasalsabila/kamus-alay/master/colloquial-indonesian-lexicon.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>slang</th>\n",
       "      <th>formal</th>\n",
       "      <th>In-dictionary</th>\n",
       "      <th>context</th>\n",
       "      <th>category1</th>\n",
       "      <th>category2</th>\n",
       "      <th>category3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>woww</td>\n",
       "      <td>wow</td>\n",
       "      <td>1</td>\n",
       "      <td>wow</td>\n",
       "      <td>elongasi</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aminn</td>\n",
       "      <td>amin</td>\n",
       "      <td>1</td>\n",
       "      <td>Selamat ulang tahun kakak tulus semoga panjang...</td>\n",
       "      <td>elongasi</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>met</td>\n",
       "      <td>selamat</td>\n",
       "      <td>1</td>\n",
       "      <td>Met hari netaas kak!? Wish you all the best @t...</td>\n",
       "      <td>abreviasi</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>netaas</td>\n",
       "      <td>menetas</td>\n",
       "      <td>1</td>\n",
       "      <td>Met hari netaas kak!? Wish you all the best @t...</td>\n",
       "      <td>afiksasi</td>\n",
       "      <td>elongasi</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>keberpa</td>\n",
       "      <td>keberapa</td>\n",
       "      <td>0</td>\n",
       "      <td>Birthday yg keberpa kak?</td>\n",
       "      <td>abreviasi</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15001</th>\n",
       "      <td>gataunya</td>\n",
       "      <td>enggak taunya</td>\n",
       "      <td>0</td>\n",
       "      <td>Ini kaya nenek2 ya beb gataunya agnezz @yugime...</td>\n",
       "      <td>akronim</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15002</th>\n",
       "      <td>gtau</td>\n",
       "      <td>enggak tau</td>\n",
       "      <td>0</td>\n",
       "      <td>Stidaknya mrka may berkarya Dan berusaha yg tr...</td>\n",
       "      <td>akronim</td>\n",
       "      <td>abreviasi</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15003</th>\n",
       "      <td>gatau</td>\n",
       "      <td>enggak tau</td>\n",
       "      <td>0</td>\n",
       "      <td>Ih gatau malu</td>\n",
       "      <td>akronim</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15004</th>\n",
       "      <td>fans2</td>\n",
       "      <td>fan-fan</td>\n",
       "      <td>0</td>\n",
       "      <td>Jkt48 adalah tempat di mana sesama fans saling...</td>\n",
       "      <td>reduplikasi</td>\n",
       "      <td>naturalisasi</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15005</th>\n",
       "      <td>gaharus</td>\n",
       "      <td>enggak harus</td>\n",
       "      <td>0</td>\n",
       "      <td>belajar tuh bisa dimana aja gaharus belajar di...</td>\n",
       "      <td>akronim</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15006 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          slang         formal  In-dictionary  \\\n",
       "0          woww            wow              1   \n",
       "1         aminn           amin              1   \n",
       "2           met        selamat              1   \n",
       "3        netaas        menetas              1   \n",
       "4       keberpa       keberapa              0   \n",
       "...         ...            ...            ...   \n",
       "15001  gataunya  enggak taunya              0   \n",
       "15002      gtau     enggak tau              0   \n",
       "15003     gatau     enggak tau              0   \n",
       "15004     fans2        fan-fan              0   \n",
       "15005   gaharus   enggak harus              0   \n",
       "\n",
       "                                                 context    category1  \\\n",
       "0                                                    wow     elongasi   \n",
       "1      Selamat ulang tahun kakak tulus semoga panjang...     elongasi   \n",
       "2      Met hari netaas kak!? Wish you all the best @t...    abreviasi   \n",
       "3      Met hari netaas kak!? Wish you all the best @t...     afiksasi   \n",
       "4                               Birthday yg keberpa kak?    abreviasi   \n",
       "...                                                  ...          ...   \n",
       "15001  Ini kaya nenek2 ya beb gataunya agnezz @yugime...      akronim   \n",
       "15002  Stidaknya mrka may berkarya Dan berusaha yg tr...      akronim   \n",
       "15003                                      Ih gatau malu      akronim   \n",
       "15004  Jkt48 adalah tempat di mana sesama fans saling...  reduplikasi   \n",
       "15005  belajar tuh bisa dimana aja gaharus belajar di...      akronim   \n",
       "\n",
       "          category2 category3  \n",
       "0                 0         0  \n",
       "1                 0         0  \n",
       "2                 0         0  \n",
       "3          elongasi         0  \n",
       "4                 0         0  \n",
       "...             ...       ...  \n",
       "15001             0         0  \n",
       "15002     abreviasi         0  \n",
       "15003             0         0  \n",
       "15004  naturalisasi         0  \n",
       "15005             0         0  \n",
       "\n",
       "[15006 rows x 7 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "asd"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "82ed002fa2d4956f5c6aec99bcefe0f73a9f79882f3c9e2319b14958a5896ac5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
